# Experiment with validation on train set and on a test set

# Variable: number of training epochs passed from training start
# Learning rate: 0.1
# Nodes in the hidden layer: 80
# Epochs: 60
# Train set size: 26999
# Test set size: 15001

epochs,trainerror,testerror
1,0.07785473536056892,0.07983333333333334
2,0.057742879365902444,0.06028571428571428
3,0.04611281899329605,0.048952380952380956
4,0.039668135856883585,0.043404761904761904
5,0.03551983406792844,0.04080952380952381
6,0.03244564613504204,0.03788095238095238
7,0.02755657616948776,0.033595238095238095
8,0.026260231860439274,0.032785714285714286
9,0.026297270269269233,0.032785714285714286
10,0.02377865846883218,0.030285714285714287
11,0.022741583021593393,0.030095238095238095
12,0.020815585762435647,0.027904761904761904
13,0.02140820030371495,0.028904761904761905
14,0.019408126226897294,0.027071428571428573
15,0.01977851031519686,0.0275
16,0.01877847327678803,0.026738095238095238
17,0.016704322382310455,0.024880952380952382
18,0.01544501648209193,0.02407142857142857
19,0.01511167080262232,0.023285714285714285
20,0.013852364902403793,0.02242857142857143
21,0.013741249675913923,0.023214285714285715
22,0.012518982184525353,0.02142857142857143
23,0.012222674913885699,0.02157142857142857
24,0.011815252416756176,0.02111904761904762
25,0.012037482869735916,0.021142857142857144
26,0.01100040742249713,0.02035714285714286
27,0.010704100151857476,0.02
28,0.010592984925367607,0.019714285714285715
29,0.01022260083706804,0.019452380952380954
30,0.009926293566428386,0.019166666666666665
31,0.009963331975258343,0.019095238095238096
32,0.009370717433979036,0.018904761904761903
33,0.009259602207489167,0.018833333333333334
34,0.008963294936849513,0.018404761904761906
35,0.008592910848549946,0.018333333333333333
36,0.008185488351420423,0.017666666666666667
37,0.008037334716100596,0.017666666666666667
38,0.007852142671950812,0.017452380952380952
39,0.007629912218971073,0.017595238095238094
40,0.007518796992481203,0.017333333333333333
41,0.0074447201748212895,0.01719047619047619
42,0.00733360494833142,0.017261904761904763
43,0.007259528130671506,0.01730952380952381
44,0.007185451313011593,0.017261904761904763
45,0.0070743360865217235,0.017023809523809524
46,0.0069261824512018965,0.017047619047619048
47,0.0068521056335419835,0.016976190476190475
48,0.0068521056335419835,0.016976190476190475
49,0.0068521056335419835,0.017023809523809524
50,0.0067780288158820695,0.017047619047619048
51,0.0067039519982221565,0.01680952380952381
52,0.0065557983629023295,0.016761904761904763
53,0.0065557983629023295,0.01669047619047619
54,0.006518759954072373,0.01669047619047619
55,0.0064817215452424165,0.01680952380952381
56,0.0064076447275825035,0.016714285714285713
57,0.006370606318752546,0.016595238095238097
58,0.006370606318752546,0.01657142857142857
59,0.0063335679099225895,0.0165
